# 음주운전 예방을 위한 주취자 행동 감지 및 차량 접근 분석 시스템
**MinoriDUI-Report**
**C011058 김지원**

---

## 목차
1. [개요](#개요)  
   1.1 [프로젝트 개요](#프로젝트-개요)  
   1.2 [프로젝트의 산출물](#프로젝트의-산출물)  
   1.3 [정의, 약어](#정의-약어)

2. [자원 및 일정 예측](#자원-및-일정-예측)  
   2.1 [자원](#자원)  
   2.2 [일정](#일정)

3. [조직 구성 및 인력 배치](#조직-구성-및-인력-배치)  
   3.1 [조직 구성](#조직-구성)  
   3.2 [직무 기술](#직무-기술)

4. [WBS](#wbs)

5. [기술관리 방법](#기술관리-방법)  
   5.1 [변경 관리](#변경-관리)  
   5.2 [위험 관리](#위험-관리)  
   5.3 [비용 및 진도 관리](#비용-및-진도-관리)  
   5.4 [문제점 해결 방안](#문제점-해결-방안)

6. [표준 및 개발 절차](#표준-및-개발-절차)  
   6.1 [개발 방법론](#개발-방법론)

7. [검토 회의](#검토-회의)  
   7.1 [검토회 일정](#검토회-일정)  
   7.2 [검토회 진행 방법](#검토회-진행-방법)  
   7.3 [검토회 후속 조치](#검토회-후속-조치)

8. [개발 환경](#개발-환경)

9. [성능 시험 방법](#성능-시험-방법)

10. [문서화](#문서화)

11. [유지보수](#유지보수)

12. [설치, 인수](#설치-인수)

13. [참고문헌 및 부록](#참고문헌-및-부록)

---

## 1. 개요
### 1.1 프로젝트 개요
본 프로젝트 **“MinoriDUI”** 는 **음주운전 예방**을 목표로, **주취자 행동**과 **차량 접근**을 **Edge 디바이스**에서 **실시간** 감지하여 위험을 사전에 차단하고자 합니다.  
- **주요 특징**  
  - 딥러닝 모델(YOLOv8, Pose Estimation, LSTM) 결합을 통한 주취자 행동 감지  
  - 차량 문 열림, 운전자 접근 시점 등 사전 경고 시스템  
  - Rust 기반 Edge Computing 최적화(실시간 처리 및 비용 절감)

### 1.2 프로젝트의 산출물
- **스마트 CCTV 시스템(MVP)**
  - 주취자 행동 및 차량 접근 이벤트를 실시간으로 파악하고 경고  
  - 웹 대시보드(경고 UI, 이벤트 로그, 통계 등)
- **Edge Device용 최적화 모델**
  - TensorRT/INT8 양자화 등 최적화된 모델(5~10FPS, 지연시간 300ms 이하 목표)
- **프로젝트 보고서 및 문서**
  - 제안서(본 문서), 사용자 매뉴얼, 개발 문서, 유지보수 가이드 등

### 1.3 정의, 약어
- **주취자(intoxicated_person)**:  
  만취, 혹은 정상 보행이 어려운 상태의 사람  
- **Edge Computing**:  
  중앙 클라우드 대신 현장에서 데이터를 처리하는 방식  
- **LSTM**:  
  Long Short-Term Memory, 시계열 데이터를 처리하는 딥러닝 모델  
- **PoC**:  
  Proof of Concept, 개념 검증 단계

---

## 2. 자원 및 일정 예측
### 2.1 자원

#### 가. 인력
- **개발 인력(1인)**:
  - Design : 김지원
  - ML Engineer : 김지원
  - Rust Engineer : 김지원
  - FE Engineer : 김지원
  - Design : 김지원
- **관제 업무 담당**:  
  - 주취자·차량 이벤트 검증, 운영 모니터링

#### 나. 비용
- **하드웨어**:  
  - Edge Device(예: Jetson Nano) 1~2대  | 학교 여유분 체크
  - 테스트용 CCTV 카메라(선택적)
- **클라우드/서버 비용**:  
  - 모델 학습 시 Google Colab, AWS EC2, 또는 GPU 서버 임대  
- **운영 비용**:  
  - 데이터 관리, 유지보수, 성능 모니터링에 필요한 최소 예산

### 2.2 일정
- **Phase 1 (Week 1~15)**: MVP 구축  
  - 핵심 기능: YOLO + Pose + LSTM, Edge 디바이스 초기 세팅, UI 프로토타입  
  - 중간 발표(Week 15)
- **Phase 2 (Week 16~30)**: 고도화 & 확장  
  - 번호판 인식, 멀티 카메라 지원, MLOps 도입  
  - 최종 발표(Week 30)
 
---

## 3. 조직 구성 및 인력 배치

### 3.1 조직 구성

| 직책       | 이름     | 주요 역할 및 책임                                             |
|------------|---------|--------------------------------------------------------------|
| PM(총괄)   | 김지원  | - 전체 일정 및 예산 관리<br>- 기술 의사결정 및 위험 관리      |
| 딥러닝 개발 | 김지원  | - YOLOv8/Pose/LSTM 모델 개발 및 튜닝<br>- 데이터셋 수집 및 전처리 |
| 시스템 개발(Rust) | 김지원  | - Rust-Python 연동 구조 설계<br>- Edge Device 최적화(TensorRT 등) |
| UI/UX 담당 | 김지원  | - 웹 대시보드 설계 및 구현<br>- 사용자 인터페이스/경고 시각화 |

### 3.2 직무 기술
- **딥러닝 개발 담당**  
  - YOLO 모델 파인튜닝, Pose Estimation + LSTM 결합  
  - 데이터 증강, 모델 검증 및 성능 측정
- **시스템 개발(Rust)**  
  - Rust-Python 연동 구조 설계, INT8 양자화, TensorRT 최적화  
  - 멀티 스레딩/비동기 프로그래밍으로 실시간 처리 구현
- **프론트엔드/UI**  
  - 웹 대시보드(실시간 경고 및 로그) 구현  
  - 시각적 디자인, UX 개선

---

## 4. WBS
아래는 주요 작업을 분류한 **Work Breakdown Structure**(WBS)입니다.

1. 기획 및 요구사항 분석
1.1 요구사항 수집
1.2 데이터셋 범위 결정
1.3 성능 목표 설정
   
2. 모델 개발 및 학습
2.1 YOLOv8 파인튜닝
2.2 Pose Estimation
2.3 LSTM 분류
   
3. 시스템 개발
3.1 Rust 기반 Edge 시스템 설계
3.2 Python 연동(FI/IPC)
3.3 UI/UX 대시보드 구현

4. 통합 및 테스트
4.1 파일럿 테스트(실내, 실외)
4.2 오탐/미탐 사례 분석
4.3 최적화 및 오류 수정
   
5. 최종 발표 및 문서화
5.1 운영 가이드 작성
5.2 최종 보고서 및 발표 자료

---

## 5. 기술관리 방법
### 5.1 변경 관리
- 기능 추가/삭제, 요구사항 변경 시, **PM** 승인 후 Git 이슈/브랜치로 관리  
- 변경 요청서(Change Request) 작성 후 주요 이해관계자 검토

### 5.2 위험 관리
- **주요 위험 요인**: Edge 디바이스 성능 부족, 데이터 부족, 예산 초과 등  
- **대응 방안**: 사전 시뮬레이션, 백업 데이터 확보, 비용 모니터링

### 5.3 비용 및 진도 관리
- 매주 혹은 격주 단위로 **예산 소모**와 **진척도** 점검  
- 이상 징후(예: 성능 미달, 일정 지연) 발견 시 즉시 공유

### 5.4 문제점 해결 방안
- **기술 자문**: 문제가 해결되지 않을 경우, 외부 전문가 컨설팅  
- **긴급 회의**: 중대한 이슈 발생 시 PM 주도로 회의 개최 및 신속 결정

---

## 6. 표준 및 개발 절차
### 6.1 개발 방법론
- **애자일(Agile) 접근**:  
  - 매주/격주 스프린트로 계획-개발-테스트-리뷰 과정을 반복  
  - 빠른 피드백으로 모델 성능 및 시스템 품질 개선

---

## 7. 검토 회의

본 프로젝트는 1인 체제로 진행되므로, 정기적인 자체 점검(주간 또는 격주)과 필요 시 외부 자문을 통해 검토를 진행한다.

### 7.1 검토회 일정
- **주간/격주 자체 검토**: 
  - Git Issue나 노션 등에 작업 현황을 기록하고, 다음 주(혹은 2주)간 작업 계획을 수립
  - 모델 성능, Edge 디바이스 추론 결과, UI 개선 사항 등을 체크
- **중간/최종 발표 전**: 
  - 발표 자료, 데모 준비 상황을 집중적으로 점검

### 7.2 검토회 진행 방법
- **자체 검토**: 
  - 본인이 진행 상황을 문서화(주간 보고서)하고, 주요 문제점이나 개선 사항을 정리
  - 이슈 우선순위를 재조정하여 차기 작업에 반영
- **외부 자문(옵션)**:
  - 지도교수 또는 업계 전문가에게 피드백을 요청
  - 온라인/오프라인 미팅 후 개선 사항을 프로젝트 문서에 반영

### 7.3 검토회 후속 조치
- **회고(Review) 기록**:
  - 검토 과정에서 나온 이슈와 해결책을 간단히 요약
  - 추후 반복되는 문제 방지를 위해 문서화
- **액션 아이템 할당**:
  - 다음 검토회 전까지 해결해야 할 과제를 정의하고, 우선순위와 기한 설정
- **결과 공유**:
  - 진행 상황과 해결 내역을 주간 보고서 또는 노션, Git Issue 등에 업데이트

---

## 8. 개발 환경
- **하드웨어**: Jetson Nano / Xavier, 테스트용 CCTV 카메라  
- **소프트웨어**:  
  - Python 3.8 이상, Rust 1.6x 이상  
  - YOLOv8, PyTorch/TensorRT, ONNXRuntime  
  - Web 대시보드(React/Vue 등)  
- **툴**:  
  - Git + GitHub / GitLab  
  - Google Colab 또는 AWS EC2 (GPU)  
  - 협업: Notion, JIRA, Slack 등
 
---

## 9. 성능 시험 방법
1. **객체 검출 정확도 평가**  
   - mAP(Mean Average Precision), Precision/Recall, F1 Score 측정  
2. **실시간 성능 테스트**  
   - Edge 디바이스에서 FPS, Latency 측정  
   - 다양한 조도/날씨 환경에서 반복 측정  
3. **오탐/미탐 분석**  
   - Confusion Matrix, 임계값(Confidence threshold) 조정

---

## 10. 문서화
- **개발 문서**:  
  - 모델 구조/하이퍼파라미터, Edge 시스템 구조, API 명세서  
- **사용자 매뉴얼**:  
  - 관제 대시보드 사용 가이드, 경고 대응 절차  
- **운영 및 유지보수 문서**:  
  - Edge 디바이스 설치/설정 방법, 로그 모니터링 지침

---

## 11. 유지보수
- **정기 점검**:  
  - 모델 재학습(데이터 추가 시), 디바이스 펌웨어 업데이트  
- **버그 관리**:  
  - Git Issue 등록 → 우선순위 분류 → 수정 후 테스트  
- **지속적인 성능 모니터링**:  
  - Edge 디바이스 성능 로그(온도, 메모리 등), FPS/Latency 실시간 체크

---

## 12. 설치, 인수
- **설치 절차**  
  1. Edge 디바이스 기본 설정 (OS, Python, Rust 설치)  
  2. 모델/라이브러리 다운로드 (YOLOv8, TensorRT 등)  
  3. 웹 대시보드 배포 (Docker or Serverless 방식)  
- **인수인계**  
  - 운영 매뉴얼, Troubleshooting 가이드 공유  
  - 담당자별 교육(관제 요원, 개발자)

---

## 13. 참고문헌 및 부록
- **주요 참고 링크**  
  - [국토교통부 교통안전 보고서](https://www.koroad.or.kr/main/board/6/301735/board_view.do)  
  - [오산시 선별 관제 시스템](https://www.ajunews.com/view/20240219150226744)  
  - [영국 Acusensus AI 카메라](https://www.digitalbizon.com/news/articleView.html?idxno=2338614)  
- **부록**  
  - 추가 데이터셋(UCSD Anomaly), 시뮬레이션 환경 설정 스크린샷, 모델 학습 로그 등

---

# 부록: 상세 구현 계획

## 배경 및 도전 과제
### 음주운전 현황과 사회적 비용
- 연간 수만 건 이상의 음주운전 사고, 재범률 높음 → 사전 예방 필요  
- 장기적인 사회적 비용(의료비, 보험료, 생산성 손실) 부담이 큼  

### 범죄 예방 프로그램 필요성
- 사고 전 단계에서 위험 감지 및 조기 대응  
- 기존 CCTV 관제 방식은 관제 요원 의존도가 높고, 인력·예산 부담 큼  

### 프로젝트 목표
- **주취자 행동** + **차량 접근** 실시간 감지, Edge 기반 경고 시스템 구축  
- 실환경에서 **지연 시간 200ms 이내**, 안정적인 5~10 FPS 보장  

---

## 경쟁 모델 분석
- **대한민국 지자체 CCTV 선별 관제** → 종합적 범죄 분석이 가능하나 음주운전 특화 성능은 낮음  
- **영국 Acusensus AI 카메라** → 운전자만 분석, 차량 외부 상황 인식 한계  
- **호주 ECU 연구팀** → 차량 내부 AI 카메라, 다양한 외부 시나리오에 한계  

**차별화:**  
- Edge Device로 실시간 처리 (비용 절감 + 지연 시간 최소화)  
- 차량 접근(문 열림, 운전석 진입)과 주취자 행동을 동시에 분석  

---

## PoC 수행 결과
- **Baseline vs Mixup 증강 실험**: 성능 개선 미미, Baseline 유지  
- **Hyperparameter Tuning**(train7) → mAP 0.852 달성  
- **Tracking + Pose + LSTM** 파이프라인 테스트 → 주취자 vs 일반인 약 75% 분류 정확도  
- **주취자 데이터 확충 필요**: 야간/우천 등 다양한 시나리오 반영 예정  

---

## 구현 세부 일정(예시)

| Week | Class                 | Major Tasks                                                      |
|-----:|:----------------------|:-----------------------------------------------------------------|
| 1    | OT                    | 프로젝트 계획서 작성                                             |
| 2    | 프로젝트 계획서 리뷰  | Baseline vs Mixup 실험, Hyperparameter Tuning                    |
| 3    | 주간 보고서 제출      | Pose + LSTM 파이프라인 구축(Python)                              |
| 4    | 제안서 발표(1학기)    | 데이터 확보 및 라벨링, LSTM 모델 분석, Rust-Python 연동 기본 PoC 설계, 문서화 구조 확립 |
| 5    | 주간 보고서 제출      | LSTM 모델 재학습 및 튜닝, Rust-Python 연동 PoC 구현, 초기 결과 분석, 중간 문서화 |
| 6    | 주간 보고서 제출      | YOLOv8 추가 학습 (Fine-Tuning), 차량 접근 이벤트 로직 개발, Edge Device 초기 세팅 |
| 7    | 주간 보고서 제출      | -                                                               |
| 8    | 중간 발표(1학기)      | TensorRT/ONNX 최적화 작업, Rust 통합 설계 구체화, UI 기능 보강      |
| 9    | 주간 보고서 제출      | 실시간 시퀀스 처리 최적화, 데이터 증강 및 도메인 어댑테이션, 오탐/미탐 사례 분석 |
| 10   | 주간 보고서 제출      | 기본 파일럿 테스트 (1부), UI/UX 초기 개선, 성능 Benchmark 측정       |
| 11   | 주간 보고서 제출      | 기본 파일럿 테스트 (2부), UI/UX 추가 개선, 성능 개선 및 안정화 초기 단계 |
| 12   | 주간 보고서 제출      | 시스템 안정화 작업, 오탐·미탐 최적화                              |
| 13   | 주간 보고서 제출      | 시스템 안정화 완료 및 최종 버그 수정, 중간 발표 자료 최종 정리, 최종 오탐/미탐 최적화 결과 검토 |
| 14   | 주간 보고서 제출      | -                                                               |
| 15   | 최종 발표(1학기)      | 실시간 데모 시연, 성능 평가 발표                                   |

---

# 1주차 작업 보고서

## 1. Baseline vs Mixup 실험 요약

### Objective
- **기존 YOLOv8n 모델**에서 Mosaic 증강(**Baseline**)과 **Mixup 증강**이 객체 검출 성능(mAP@0.5, Validation Loss)에 미치는 영향을 비교

### Experimental Setup
- **모델**: `yolov8n.pt (pretrained)`
- **데이터**: Roboflow car_driver_seat (5 classes)
- **Epochs**: 10
- **이미지 크기**: 640
- **비교 대상**: Mosaic-only (Baseline) vs Mosaic+Mixup
- **측정 지표**: mAP@0.5, Validation Loss

### Results

|       Metric       | Baseline (Mosaic) | Mixup (Mosaic+Mixup) | Difference       |
|:------------------:|:-----------------:|:--------------------:|:----------------:|
| **Final mAP@0.5**  |      0.835        |        0.852         |  +0.017 *(미미)* |
| **Final Val Loss** |      2.547        |        2.537         |  -0.010 *(동일)* |

![63EDE4DA-5C4A-4816-9A34-E348993E358E_1_105_c](https://github.com/user-attachments/assets/25d38d53-f9fc-4f2c-9039-32636e47d9a5)
![5D211575-854C-4EB6-87DB-546E05937B4E](https://github.com/user-attachments/assets/3909d3de-177f-4286-aa96-674967b8ff3e)

- **Conclusion**  
  - Mixup 증강은 실험 데이터 환경에서 **유의미한 성능 개선 효과 없음**
  - → **Baseline 유지** 결정

---

## 2. Hyperparameter Tuning (train4 – train7)

### Objective
- 학습률(**lr**)과 배치 크기(**batch**)의 조합이 최종 mAP와 Validation Loss에 미치는 영향 비교

### Setup
| Run    | lr      | Batch | Folder              |
|--------|---------|-------|---------------------|
| train4 | 0.001   | 4     | `runs/detect/train4` |
| train5 | 0.001   | 8     | `runs/detect/train5` |
| train6 | 0.0001  | 4     | `runs/detect/train6` |
| train7 | 0.0001  | 8     | `runs/detect/train7` |

### Results (Epoch 10 기준)
| Run    | mAP@0.5 | Val Box Loss | Best? | Comment                |
|--------|---------|--------------|-------|------------------------|
| train4 | 0.835   | 0.950        |       | 낮은 성능              |
| train5 | 0.852   | 0.920        | ✅     | 높은 mAP + 낮은 Loss   |
| train6 | 0.833   | 0.950        |       | 낮은 성능              |
| train7 | 0.852   | 0.918        | ✅     | **최고 성능 (선택)**   |

![E50A0A3A-9AC6-413E-BC7B-FC68FE4E69CD](https://github.com/user-attachments/assets/595c1975-28cc-4689-a402-34fc4734d6c5)
![B7AF0282-79E4-41CF-B74D-FD0806040F6F](https://github.com/user-attachments/assets/71dc7ea2-2fc8-4af7-8d76-a13991a268c5)

> **최종 결론**  
> - `train7 (lr=0.0001, batch=8)` 이 **최적** 하이퍼파라미터로 확정

---
## Pipeline Test 결과

- **Tracking + Pose 파이프라인 정상 작동 확인**  
- 테스트 영상(`/content/PXL_20241123_090617530_3fps.mp4`) 158프레임 처리  
- 총 **4명의 트랙 ID** 생성 → Track 2(6 frames), Track 4(24 frames), Track 10(67 frames), Track 19(13 frames)  
- 각 ID별 Pose keypoint 시퀀스(최대 90프레임) 정상 수집 → 다음 단계(LSTM) 데이터 준비 완료

---

# 1주차 작업 보고서

---

## 1. Baseline vs Mixup 실험 요약

### 목적
- **기존 YOLOv8n 모델**에서 Mosaic 증강(**Baseline**)과 **Mixup 증강**이 객체 검출 성능(mAP@0.5, Validation Loss)에 미치는 영향을 비교

### 개요
- **모델**: `yolov8n.pt (pretrained)`
- **데이터**: Roboflow car_driver_seat (5 classes)
- **Epochs**: 10
- **이미지 크기**: 640
- **비교 대상**: Mosaic-only (Baseline) vs Mosaic+Mixup
- **측정 지표**: mAP@0.5, Validation Loss

### Results

|       Metric       | Baseline (Mosaic) | Mixup (Mosaic+Mixup) | Difference         |
|:------------------:|:-----------------:|:--------------------:|:------------------:|
| **Final mAP@0.5**  |      0.835        |        0.852         |  +0.017 *(미미)*   |
| **Final Val Loss** |      2.547        |        2.537         |  -0.010 *(동일)*   |

![63EDE4DA-5C4A-4816-9A34-E348993E358E_1_105_c](https://github.com/user-attachments/assets/25d38d53-f9fc-4f2c-9039-32636e47d9a5)
![5D211575-854C-4EB6-87DB-546E05937B4E](https://github.com/user-attachments/assets/3909d3de-177f-4286-aa96-674967b8ff3e)

- **Conclusion**  
  - Mixup 증강은 실험 데이터 환경에서 **유의미한 성능 개선 효과 없음**
  - → **Baseline 유지** 결정

---

## 2. Hyperparameter Tuning (train4 – train7)

### 목적
- 학습률(**lr**)과 배치 크기(**batch**)의 조합이 최종 mAP와 Validation Loss에 미치는 영향 비교

### 설정

| Run    | lr      | Batch | Folder              |
|--------|---------|-------|---------------------|
| train4 | 0.001   | 4     | `runs/detect/train4` |
| train5 | 0.001   | 8     | `runs/detect/train5` |
| train6 | 0.0001  | 4     | `runs/detect/train6` |
| train7 | 0.0001  | 8     | `runs/detect/train7` |

### 결과 (Epoch 10 기준)

| Run    | mAP@0.5 | Val Box Loss | Comment                |
|--------|---------|--------------|------------------------|
| train4 | 0.835   | 0.950        | 낮은 성능              |
| train5 | 0.852   | 0.920        | 높은 mAP + 낮은 Loss   |
| train6 | 0.833   | 0.950        | 낮은 성능              |
| train7 | 0.852   | 0.918        | **최고 성능 (선택)**   |

![E50A0A3A-9AC6-413E-BC7B-FC68FE4E69CD](https://github.com/user-attachments/assets/595c1975-28cc-4689-a402-34fc4734d6c5)
![B7AF0282-79E4-41CF-B74D-FD0806040F6F](https://github.com/user-attachments/assets/71dc7ea2-2fc8-4af7-8d76-a13991a268c5)

> **최종 결론**  
> - `train7 (lr=0.0001, batch=8)` 이 **최적** 하이퍼파라미터로 확정

---

## 3. Pipeline Test 결과 (Tracking + Pose)

- **Tracking + Pose 파이프라인 정상 작동 확인**  
- 테스트 영상(`PXL_20241123_090617530_3fps.mp4`, 총 158프레임)
  - 추적된 **4명(Track ID: 2, 4, 10, 19)**  
  - 각 ID별로 6 / 24 / 67 / 13 프레임 분량의 Pose 키포인트 추출
- **Pose keypoint**: 17개 관절 × 2D → (34,) 벡터
- 시퀀스 데이터가 정상 저장됨을 확인 → **2.3 LSTM 학습** 준비 완료

---

## 4. LSTM 기반 분류

4.1 소규모 데이터 실험
	•	90프레임(약 3초) 간격으로 구성된 소규모 시퀀스
	•	약 75% 정확도 달성
```
Epoch 1 loss:0.6917
Epoch 2 loss:0.6785
Epoch 3 loss:0.6749
Epoch 4 loss:0.6660
Epoch 5 loss:0.6564
Epoch 6 loss:0.6457
Epoch 7 loss:0.6335
Epoch 8 loss:0.6190
Epoch 9 loss:0.5403
Epoch 10 loss:0.6650
▶ Test Accuracy: 0.75
```

### 4.2 Confusion Matrix & Classification Report

- **결론**:  
  - 현재 테스트 세트는 클래스 수가 매우 적어 drunk 클래스 샘플이 1개뿐임  
  - 향후 drunk 영상 데이터를 추가하면 모델 성능 개선 가능(현재 75퍼센트)

---

## 결론 및 다음 계획

1. **Baseline vs Mixup**  
   - Mixup 증강은 유의미한 성능 개선 효과가 없어 → **Baseline 유지**

2. **Hyperparameter Tuning**  
   - `train7 (lr=0.0001, batch=8)`가 최종 선정됨

3. **Tracking + Pose 파이프라인**  
   - 정상 작동하여 Pose 시퀀스 데이터 수집에 성공

4. **LSTM 분류**  
   - 소규모 데이터로 약 75% 정확도를 달성하였으나, drunk 데이터 부족으로 Recall 개선이 필요함

### 향후 진행 계획
- **차량 상호작용 이벤트 감지 (2.4 단계)**:  
  - 차량 접근, 운전석 문 열림, 차량 이동 이벤트를 감지하여 화면 색상(노랑/핑크/빨강)으로 시각화
- **데이터 확충**:  
  - 주취자(drunk)와 일반인(sober) 영상 데이터를 각각 추가 확보하여 LSTM 모델을 재학습
- **최종 PoC**:  
  - 전체 파이프라인(Detection → Tracking → Pose → LSTM → 이벤트 감지)을 통합한 PoC 완성
- **추가 계획 (Edge/Rust PoC)**:  
  - 후속 단계로, 학습된 모델을 ONNX 변환하여 Rust 기반 Edge 환경에서의 실시간 추론 PoC 진행 예정

---

> **요약**:  
> 이번 1주차 작업에서는 기본 검출 및 추적, 그리고 소규모 LSTM 분류 PoC를 성공적으로 완료하였으며, 다음 단계에서는 차량 이벤트 감지 및 데이터 확충, 나아가 Edge Computing 적용 계획을 수립할 예정입니다.

---








#최초 제안서

## 1. 배경 및 도전 과제

### 1.1 음주운전 현황과 사회적 비용
- **통계 및 비용:**
  - 최신 교통안전 보고서에 따르면, 연간 [수만 건](https://www.koroad.or.kr/main/board/6/301735/board_view.do?&cp=1&listType=list&bdOpenYn=Y&bdNoticeYn=N) 이상의 음주운전 사고가 발생하며, 이로 인한 인명피해는 연간 [수백 명](https://www.koroad.or.kr/main/board/6/89587/board_view.do?&cp=1&listType=list&bdOpenYn=Y&bdNoticeYn=N) 경제적 손실은 [수백억 원](https://www.insnews.co.kr/m/news_view.php?firstsec=5&secondsec=53&num=56208)에 달하는 것으로 분석됩니다.
  - 재범률이 높은 음주운전은 단순 사고 발생뿐 아니라 장기적인 사회적 비용(의료비, 보험 비용, 생산성 손실 등)을 야기합니다.

### 1.2 범죄 예방 프로그램의 필요성
- **사고 전 조기 차단:**
  - 사고 또는 범죄의 시작과 종결 사이의 시간 간격이 길수록, 조기 경고 시스템을 통한 사전 차단이 효과적입니다.
  - 특히, **음주운전**의 경우, 주취자가 사고를 내기 전 조기에 인지함으로써 잠재적 사고를 미연에 방지할 수 있습니다.

### 1.3 현장 개선의 필요성
- **관제 요원의 부담:**  
  다수의 CCTV 영상을 실시간으로 모니터링하는 것은 인력 부족 문제와 맞물려 관제 요원에게 과도한 부담을 주며, 인간의 한계로 인해 주취자나 위험 상황을 놓칠 가능성이 큽니다.

- **예산 부담:**  
  다수의 CCTV 운영 및 관제 인력 확보에 따른 지속적인 예산 부담이 발생하고 있습니다. 특히, 많은 스마트 CCTV 시스템이 클라우드 기반 서비스를 활용하여 영상 데이터를 전송, 저장, 처리하는 구조로 운영되기 때문에, 이로 인한 지속적인 클라우드 비용이 예산 부담을 더욱 가중시키고 있습니다.
  [관련 기사](https://www.donga.com/news/Society/article/all/20231031/121960976/1)

### 1.4 대상 사용자 및 이해관계자
- **주요 대상:**  
  - **현장 운영 전문가:**  
    - **관제 요원**, **교통 경찰**, **보안 담당자** 등 실제 CCTV 운영과 단속 업무를 수행하는 인력.  
    - 이들은 제한된 인력과 자원으로 다양한 위험 상황을 모니터링해야 하며, 본 시스템을 통해 신속하고 효과적인 대응을 기대할 수 있습니다.
  
  - **시스템 운영 및 관리 책임자:**  
    - 지방 정부, 공공 안전 기관, 또는 민간 보안 업체의 관리자들이 포함됩니다.  
    - 이들은 시스템의 효율성과 비용 절감을 통해 전반적인 도시 안전 관리 및 범죄 예방에 기여할 수 있습니다.
  
- **이해관계자:**  
  - **국민 안전:**  
    - 최종적으로 본 시스템은 대한민국 국민의 안전을 강화하고, 음주운전으로 인한 인명 피해 및 경제적 손실을 줄이는 데 기여합니다.

### 1.5 프로젝트 목표
- **주요 목표:**
  - **음주 운전 조기 파악 및 사고 전 검거:** 주취자 행동(예: 보행 속도, 자세 변화, 비정상적 움직임 등 객관적 기준에 따른 정의)과 차량 접근(예: 운전석 문 열림)을 실시간으로 감지하여, 단계별 경고(빨간/노란/분홍 화면 전환)를 통해 빠른 대응을 유도합니다.
  - **Edge Device 기반 실시간 추론:** 제한된 자원 내에서도 높은 효율의 실시간 처리를 달성하기 위해, Edge Computing 기술을 적용합니다.

---

## 2. 경쟁 모델 분석

### A) 대한민국 각 지역 CCTV 실시간 선별 관제 시스템 (예시 : 오산시)
- **사례 설명:**
  오산시와 같은 일부 지자체에서는 기존 CCTV 중 고화질 CCTV들을 활용하여, 범죄 의심 정도를 실시간으로 선별하고 관제하는 시스템을 도입하였습니다.
- **기술적 접근:**
  - 여러 범죄 유형(음주운전, 침입, 폭력 등)에 대해 AI 알고리즘을 적용하여 의심 수준을 분류합니다.
  - 관제 요원에게 실시간 경고 및 분류 정보를 제공하여, 우선 순위에 따라 신속한 대응이 가능하도록 지원합니다.
- **특장점 및 한계:**  
  - **장점:** 다양한 범죄 유형을 포괄하는 종합 관제 시스템으로, 여러 위협 요소를 동시에 모니터링할 수 있습니다.  
  - **한계:** 여러 이벤트를 동시에 처리하기 때문에, 특정 상황(예: 음주운전)에 특화된 분석 정확도는 상대적으로 낮을 수 있습니다.  
- **참고 링크:** 
  [대한민국 각 지역 CCTV 실시간 선별 관제 시스템 (오산시)](https://www.ajunews.com/view/20240219150226744)

#### B) 영국 Acusensus AI 카메라
- **사례 설명:**
  영국의 Acusensus AI 카메라는 운전 중 휴대폰 사용, 약물 복용, 음주 운전 등 운전자의 부적절한 행동을 실시간으로 감지하며, 현재 일부 도시에서 사용 중입니다.
- **기술적 접근:** 
  - 고해상도 영상과 AI 기반 행동 분석 알고리즘을 결합하여, 운전 중 위험 행위를 정확하게 식별합니다.  
- **특장점 및 한계:**  
  - **장점:** 운전자 행동에 대한 세밀한 분석을 통해, 음주 및 약물 복용과 같은 특정 부적절 행위를 효과적으로 감지합니다.  
  - **한계:** 운전자에게 초점을 맞춘 시스템이므로, 차량 접근 등 다른 유형의 이벤트 감지에는 한계가 있을 수 있습니다.  
- **참고 링크:**  
  [영국 Acusensus AI 카메라](https://www.digitalbizon.com/news/articleView.html?idxno=2338614)

#### C) 호주 ECU 연구팀의 AI 기반 차량 내 음주운전 감지 기술  
- **사례 설명:**  
  호주의 에디스코완대 연구팀은 차량 내에 설치된 AI 카메라를 통해, 운전자가 차량에 탑승하자마자 음주 운전 징후를 75% 이상의 확률로 감지하는 기술을 개발하였습니다.  
- **기술적 접근:**  
  - 차량 내 환경에서 운전자의 행동을 신속하게 분석하여, 음주 운전 여부를 조기에 판별합니다.
  - 실시간으로 경고를 전달하여, 운전 시작 단계에서 위험을 감지하는 데 초점을 맞춥니다.
- **특장점 및 한계:**
  - **장점:** 운전자가 차량에 탑승하는 즉시 높은 확률로 음주 운전 여부를 감지할 수 있어, 조기 경고 및 예방 효과가 큽니다.
  - **한계:** 차량 내 단일 상황에 초점을 맞추고 있어, 보다 광범위한 범죄나 다양한 위험 상황에 대한 대응은 제한적일 수 있습니다.
- **참고 링크:**
  [호주 에디스 코원 대학교 연구팀 발표 (ECU, CVPR)](https://www.aitimes.com/news/articleView.html?idxno=161640)

---

## 2.1 경쟁 모델 대비 특장점 및 차별화 요소

기존 경쟁 모델과 비교하여 다음과 같은 주요 강점을 보유하고 있습니다:

- **실시간 성능 및 반응 속도 극대화:**
  - **지연 시간 최소화:** 실제 환경에서 200ms 이하의 지연 시간을 달성하여, 위험 상황 발생 시 즉각적인 경고 및 알림 기능을 제공합니다.  
  - **높은 FPS 유지:** 다양한 환경 조건(조도, 날씨, 네트워크 상태 등)에서도 5~10 FPS의 안정적인 실시간 추론 성능을 보장합니다.  
  - **빠른 반응 속도:** 음주운전 감지 시 즉각적인 경고 전파를 통해, 사고 발생 가능성을 현저히 감소시킵니다.

- **비용 효율성 및 확장성 확보:**  
  - **총 소유 비용(TCO) 절감:** 중앙 서버 의존도를 줄임으로써 클라우드 비용, 네트워크 비용, 유지보수 비용 등에서 최대 30% 이상의 TCO 절감 효과를 기대할 수 있습니다.  
  - **높은 확장성과 유연성:** Edge Computing 기반의 시스템은 필요에 따라 쉽게 확장 및 커스터마이징할 수 있어, 다양한 환경과 요구 사항에 신속히 대응할 수 있습니다.

이와 같이, Rust 기반 Edge Computing 최적화를 통해 경쟁 모델 대비 뛰어난 성능과 비용 효율성을 제공함으로써, 음주운전 예방 및 국민 안전 강화에 크게 기여할 수 있습니다.

---

## 3. 구현

### 3.1 PoC 수행 결과 및 인사이트

3월 11일부터 3월 12일까지 이틀 동안 진행한 PoC 단계에서는 영상 속 객체들 중 사람, 자동차, 오토바이, 자동차(문 열린 상태, **음주 운전 가능성 있음**), 자동차(문 닫힌 상태)로 분류할 수 있는 ML 모델을 제작하였습니다.
로컬 CPU 환경에서 학습 속도 문제 및 발열 문제로 인해, Google Colab의 CPU로 전환하여 PoC를 진행하였습니다.

1. **데이터셋 활용 및 초기 테스트**
   - **기본 데이터셋 "car_driver_seat":**  
     - Roboflow Universe (v13, CC BY 4.0)에서 약 **7,096장**의 이미지를 활용해, `car`, `car_door_opened`, `motocycle`, `open_driver_seat`, `person` 등 **5개 클래스**를 학습 대상으로 설정하였습니다.  
     - **기본 설정**: 해상도 1024×1024, ±15° 회전, ±25% 밝기 증강 등이 이미 적용된 상태로 배포된 데이터셋을 그대로 이용해, **초기 성능**을 빠르게 확인하였습니다.
    
2. 2. **학습 로그 및 성능 측정**  
   - **학습 로그 예시**:  
     - Epoch 1~3 사이 box_loss, cls_loss, dfl_loss 등이 지속 감소하는 양상을 보였으며, 전반적으로 정상 학습 흐름이 관찰되었습니다.
     - Colab 환경에서 Batch size=16, 해상도 640×640 기준, 1 Epoch에 약 1시간 15분 소요.  
   - **객체 감지 정확도(mAP)**:  
     - 초기(5 Epoch 이내)에는 70% 이상의 mAP을 얻었습니다. 10 Epoch로 확장하면 약 90%의 mAP를 얻었습니다.
   - **추가 개선 방안**:  
     - 더 많은 Epoch, 하이퍼파라미터(LR, momentum) 조정, 데이터 증강(Flip, Mosaic) 강화 등을 통해 정확도를 높일 예정.

---

### 3.2 전체 시스템 구현 계획

이후 본 프로젝트의 전면적인 시스템 구현은 다음 세부 항목들로 구성됩니다.

#### 3.2.1 알고리즘 설계 세부 사항

1. **YOLOv8 모델 커스터마이즈**  
   - 사전학습된 YOLOv8 (nano/large 버전)을 기반으로 추가 클래스(`intoxicated_person`)를 포함하도록 파인튜닝합니다.  
   - **하이퍼파라미터 튜닝 및 데이터 증강:**  
     - 학습률(lr), 모멘텀 등 주요 하이퍼파라미터를 초기 실험 결과에 기반해 조정합니다.  2
     - Flip, Mosaic, 밝기 및 대비 조절 등의 증강 기법을 적용하여 모델의 일반화 성능을 향상시키며, 증강 효과를 수치와 사례로 평가합니다.
   - **모델 아키텍처 세부 설명:**  
     - YOLOv8의 네트워크 레이어 구성, 백본 및 헤드 구조 등 구체적 변경 사항을 다이어그램과 함께 기술합니다.  
     - Pose Estimation과 LSTM을 결합한 옵션 A와 단일 YOLO 분류 방식 옵션 B의 장단점을 비교 분석하여, 시나리오별 최적 전략을 결정합니다.

2. **주취자 행동 패턴 수치화**  
   - **옵션 A:**  
     - Pose Estimation을 통해 인체의 주요 관절 위치를 추출하고, 시계열 모델(LSTM)을 활용하여 보행 속도, 각도(기울기) 등의 정량적 지표로 주취자 행동을 수치화합니다.
   - **옵션 B:**  
     - 단일 YOLO 분류를 통해 프레임 단위로 `intoxicated_person` 라벨을 적용, 만취 여부를 판단합니다.
   - 두 옵션은 시나리오별 정확도 및 구현 난이도를 고려하여 최적의 방안을 채택합니다.

3. **Edge Computing 최적화**  
   - **저전력 디바이스 최적화:**  
     - Jetson Nano와 같은 저전력 Edge 디바이스에서 모델을 효율적으로 실행하기 위해, TensorRT, INT8 양자화(QAT/PTQ) 등의 최적화 기법을 적용합니다.
   - **성능 벤치마크:**  
     - 해상도를 320~640으로 조정하고 배치 크기를 1로 설정하여 GPU 최적화를 달성, Edge 디바이스에서 실제 FPS 및 latency를 측정하여 기록합니다.

---

#### 3.2.2 기술적 난이도 증명 및 Pain Points

본 프로젝트의 핵심 도전 과제는, 제한된 자원 환경에서 주취자와 차량 접근 같은 복합 이벤트를 실시간으로 감지하는 AI 모델을 개발하고, 이를 Rust 기반의 Edge Computing 환경에 효과적으로 이식하는 데 있습니다. 이를 위해 우리는 두 가지 측면에서 접근합니다.

**[AI 모델 최적화의 도전 과제]**  
- **모델 정확도와 일반화:**  
  - 주취자 감지와 차량 접근 이벤트의 복합 상황에서, 공개 데이터셋을 기반으로 한 모델이 다양한 환경(조도, 날씨, 카메라 각도 등)에서도 안정적인 성능을 유지해야 합니다.  
  - mAP, Precision, Recall, F1 Score 등 표준 평가 지표를 통해 성능을 검증하고, 오탐/미탐을 최소화하는 후처리 기법을 적용해야 합니다.
- **데이터 증강과 라벨 품질:**  
  - 증강 기법의 효과와 라벨의 정확도가 모델 성능에 미치는 영향을 면밀히 분석하고 개선해야 하는데, 이는 반복적인 실험과 검증이 필요합니다.

**[Rust 기반 Edge Computing 최적화의 도전 과제]**  
- **실제 Edge 환경에서의 성능 제한:**  
  - Rust를 활용한 고성능 구현은 메모리 안전성과 효율성을 제공하지만, 실제 제한된 연산 자원(예: Jetson Nano) 하에서 실시간 추론을 구현하는 것은 상당한 기술적 도전입니다.  
  - INT8 양자화, TensorRT, ONNXRuntime 등의 최적화 기법을 적용하여 목표 성능(5~10 FPS, 300ms 이하의 latency)을 달성해야 합니다.
- **통합 검증의 어려움:**  
  - 학습된 AI 모델을 Edge 디바이스에 이식한 후, 실제 환경에서의 실시간 성능과 안정성을 정량적으로 검증하는 과정은, 기존의 오프라인 테스트와는 다른 복합적인 문제들을 내포합니다.  
  - 여러 환경 조건에서의 통합 테스트와 관제 시스템 연동 시 발생할 수 있는 문제를 미리 예측하고 대응하는 것이 필수적입니다.
    
---

#### 3.2.3 데이터셋 구체성 및 다양성

1. **기본 데이터셋: car_driver_seat**
   - **출처:** Roboflow Universe (v13, CC BY 4.0)  
   - **크기:** 약 7,096장
   - **클래스:** `car`, `car_door_opened`, `motocycle`, `open_driver_seat`, `person`  
   - **특성:** 해상도 1024×1024, ±15° 회전, ±25% 밝기 증강  
   - **추가 보강:**  
     - 데이터 분포(해상도, 조도, 촬영 각도 등)를 표나 그래프로 시각적으로 제시하여, 데이터셋의 품질과 다양성을 명확히 합니다.  
     - 증강 전략(Flip, Rotation, Brightness/Contrast 조절 등) 및 그 효과를 수치와 사례를 통해 상세히 기술합니다.

2. **추가 주취자 샘플**  
   - **출처:** 본인 촬영 연출 영상과 오픈소스 이상행동 데이터셋(예: UCSD Anomaly)  
   - **목표:** 최종적으로 8,000~9,000장의 데이터를 확보  
   - **추가 보강:**  
     - 각 샘플의 촬영 환경(실내, 야외, 조도, 날씨 등)과 조건에 따른 통계 데이터를 제공하여, 모델의 일반화 성능을 강화합니다.  
     - 데이터 전처리 파이프라인의 품질 관리 및 검증 방법을 구체적으로 기술합니다.

3. **데이터 다양성 확보**
   - **다양한 환경 조건:**  
     - 실내 주차장, 야외 골목, 다양한 차량 종류, 날씨(비, 눈), 조도(낮, 밤) 등 여러 조건에서 촬영된 데이터를 포함하여, 모델의 일반화 성능을 극대화합니다.
   - **목표:**  
     - 각 조건별 샘플 분포와 품질 평가 데이터를 통해, 모델 성능 향상에 기여하는 다각적인 분석 결과를 제시합니다.

---

#### 3.2.4 평가 메트릭 및 검증 방법

1. **객체 감지 정확도**
   - **평가 지표:**
     - 각 클래스별 평균 정밀도
     - 주취자(혹은 `intoxicated_person`)와 일반인의 구분 정확도
   - **목표 수치:**
     - 예시: 정밀도 ≥ 70%, 정확도 ≥ 0.75
   - **정량적 평가 방법:**
     - 각 평가 지표에 대한 목표 수치를 명시하고, 테스트 데이터셋을 통해 반복 검증
     - 학습 및 검증 단계에서 크로스 밸리데이션을 적용해, 다양한 환경에서의 일관성을 확보

2. **실시간 성능**
   - **성능 지표:**  
     - FPS (목표: 5~10 FPS)
     - Latency (목표: 300ms 이하)
   - **측정 방법:**  
     - Edge 디바이스(예: Jetson Nano)에서 실제 영상 스트리밍 환경에서 성능 로그를 수집
     - 다양한 테스트 환경(조도, 날씨, 카메라 각도)에서 성능을 측정하여 평균치 및 최악의 경우를 기록

3. **오탐/미탐 임계값**  
   - **세부 조정:**  
     - Confidence threshold를 0.25~0.5 범위 내에서 최적의 값으로 조정
     - Non-Maximum Suppression (NMS) 등의 후처리 알고리즘을 통해 오탐과 미탐을 최소화
   - **통합 테스트 계획:**  
     - 다양한 환경(조도, 날씨, 카메라 각도)에서 통합 테스트를 실시하여, 실제 관제 시스템에서 허용 가능한 오탐/미탐 범위를 결정

---

#### 3.2.5 UI/UX 고려

1. **식별 편의성**
   - **단계별 색상 체계:**
     - 초록색: 주취자 감지
     - 노란색: 차량 접근 방지
     - 빨간색: 문 열림 감지
     - 핑크색: 차량 이동 감지
   - 직관적인 경고 아이콘과 (옵션) 사운드 알림 기능을 통해, 관제 요원이 신속히 위험 상황을 인지할 수 있도록 설계합니다.

2. **웹 대시보드**
   - **실시간 영상 및 데이터 시각화:**
     - 실시간 영상 스트리밍과 함께, 바운딩 박스 및 이벤트 로그(예: 주취자 등장 시각, 이벤트 지속 시간 등)를 표시합니다.  
     - 사용자 인터페이스(UI)는 최소한의 클릭으로 전체 상황을 파악할 수 있도록, 직관적이고 간결한 디자인으로 구성합니다.
   - **디자인 및 인터페이스 상세:**
     - 관제 요원용 웹 대시보드의 와이어프레임과 프로토타입, 사용자 여정(User Journey) 맵을 사전에 제작하고, 사용성 테스트 결과를 반영하여 최종 디자인을 확정합니다.
     - 색상, 아이콘, 경고음 등 UX 요소에 대한 상세 설계 문서를 마련합니다.

---

#### 3.2.6 파일럿 테스트

공개된 영상 스트리밍 데이터와 온라인 CCTV 데이터셋을 활용하여 시스템의 핵심 기능과 실시간 성능을 검증합니다.

- **온라인 테스트 환경 구성:**  
  - **데이터 소스 활용:**  
    - 공개 RTSP 스트리밍 영상, 온라인 CCTV 데이터셋, 또는 공공 데이터 포털에서 제공하는 라이브 스트리밍 데이터를 활용하여 실제 운영 환경과 유사한 조건에서 시스템을 테스트합니다.
  
- **시뮬레이션 기반 테스트:**  
  - 테스트 여유가 있을 경우, 다양한 환경 조건(조도, 날씨, 카메라 각도 등)을 반영할 수 있는 시뮬레이션 플랫폼을 통해 Edge 디바이스에서의 실시간 추론 및 데이터 전송 성능을 추가로 평가합니다.

---

#### 3.2.7 개인정보 보호

본 프로젝트에서 사용되는 데이터셋이 이미 공개 데이터로 제공되는 경우, 해당 데이터셋에 개인정보 보호 처리가 이미 이루어져 있다면 추가적인 얼굴 및 번호판 마스킹 작업은 생략해도 될 것이지만, 실제 CCTV 영상 등
민감 정보가 포함된 데이터를 활용할 경우, 별도의 익명화 처리(예: Gaussian Blur, 박스형 마스킹, Deep Privacy 등)를 통해 개인정보 보호를 철저히 해야 합니다.

---

#### 3.2.8 1차 피드백

피드백 결과 카메라로 차량번호를 인식해서 전달하면 빠른 대처가 가능할 것이라는 의견이 나와 반영할 예정입니다.

---

## 4. 구현 세부 일정

## 4. 구현 세부 일정(28주 기준, 15+13)

| Week | Class | Major Tasks |
|------|-------|------|
| 1    | OT | 프로젝트 계획서 작성
| 2    | 프로젝트 계획서 리뷰 | Baseline vs Mixup 실험, Hyperparameter Tuning
| 3    | 주간 보고서 제출 | Pose + LSTM 파이프라인 구축(Python)
| 4    | 제안서 발표(1학기) | 데이터 확보 및 라벨링, LSTM 모델 분석, Rust-Python 연동 기본 PoC 설계
| 5    | 주간 보고서 제출 | LSTM 모델 재학습 및 튜닝, Rust-Python 연동 PoC 구현, 초기 결과 분석
| 6    | 주간 보고서 제출 | YOLOv8 추가 학습 (Fine-Tuning), 차량 접근 이벤트 로직 개발, Edge Device 초기 세팅
| 7    | 주간 보고서 제출
| 8    | 중간 발표(1학기) | TensorRT/ONNX 최적화 작업, Rust 통합 설계 구체화, UI 기능 보강
| 9    | 주간 보고서 제출 | 실시간 시퀀스 처리 최적화, 데이터 증강 및 도메인 어댑테이션, 오탐/미탐 사례 분석
| 10    | 주간 보고서 제출 | 기본 파일럿 테스트 (1부), UI/UX 초기 개선, 성능 Benchmark 측정
| 11    | 주간 보고서 제출 | 기본 파일럿 테스트 (2부), UI/UX 추가 개선, 성능 개선 및 안정화 초기 단계
| 12    | 주간 보고서 제출 | 시스템 안정화 작업, 오탐·미탐 최적화
| 13    | 주간 보고서 제출 | 시스템 안정화 완료 및 최종 버그 수정, 중간 발표 자료 최종 정리, 최종 오탐/미탐 최적화 결과 검토
| 14    | 주간 보고서 제출 |
| 15    | 최종 발표(1학기) |

---

## 결론

본 프로젝트는 **음주운전 예방**을 목표로, **주취자 행동**과 **차량 접근**을 **Edge 디바이스**에서 **실시간** 감지 및 경고하는 스마트 CCTV 솔루션을 구현하는 것을 목적으로 합니다. 이를 통해, 기존의 단순 감지 시스템을 넘어 보다 정교한 위험 상황 예측 및 빠른 현장 대응이 가능해집니다.

**요약 및 기대 효과:**  
- 본 시스템은 사고 발생 이전에 주취자와 차량 접근을 조기에 인지하여, 신속한 대응과 위험 상황 경고를 가능하게 함으로써 범죄 예방 및 국민 안전 강화를 실현할 것입니다.
- 제안 시스템 도입 시, 음주 운전 사고를 단 10%만 줄이더라도 수십억의 재산 피해 방지 및 수십 명의 생명을 살릴 수 있습니다.
- Edge Computing으롤 저렴하게 서비스를 제공할 수 있다고 하면, 경제적&사회적 모두 이득을 가져올 수 있습니다.
- 최종적으로, 이 솔루션은 사회적 안전망을 강화하고, 향후 다양한 안전 관리 솔루션으로 확장될 수 있는 탄탄한 기반을 마련하여, 경제적·사회적 ROI 측면에서도 높은 효과를 기대할 수 있습니다.

---
