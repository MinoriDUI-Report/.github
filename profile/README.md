# 11ì£¼ì°¨ ì‘ì—… ë³´ê³ ì„œ

## ê°œìš”

ë³¸ ì£¼ì°¨ì—ì„œëŠ” ê¸°ì¡´ ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ë° feature extraction ê³¼ì •ì˜ ì „ë©´ì ì¸ ê°œì„ ì„ ìˆ˜í–‰í•˜ì˜€ë‹¤. ë˜í•œ ëª¨ë¸ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ìµœì‹  object detection ë° segmentation ëª¨ë¸ì„ ê¸°ì¡´ pipelineì— ìƒˆë¡­ê²Œ ë„ì…í•˜ì˜€ë‹¤. ì´ë¥¼ í†µí•´ downstream taskì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë” ì •í™•í•˜ê³  ì¼ê´€ëœ feature vectorë¥¼ í™•ë³´í•˜ê³ , í–¥í›„ multimodal ëª¨ë¸ ì…ë ¥ ë°ì´í„°ì˜ í’ˆì§ˆì„ ë†’ì´ëŠ” ê¸°ë°˜ì„ ë§ˆë ¨í•˜ê³ ì í–ˆë‹¤.

## ì£¼ìš” ì‘ì—… ë‚´ìš©

### 1. YOLOv8n â†’ YOLOv10n ì—…ê·¸ë ˆì´ë“œ

- ê¸°ì¡´ object detection ëª¨ë¸ë¡œ ì‚¬ìš©í•˜ë˜ **YOLOv8n**ì„ ìµœì‹  ë²„ì „ì¸ **YOLOv10n**ìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œí•˜ì˜€ë‹¤.
- YOLOv10nì€ YOLOv8 ê³„ì—´ ëŒ€ë¹„ ê²½ëŸ‰í™”ëœ architectureì™€ ì„±ëŠ¥ ìµœì í™”ë¥¼ ë°˜ì˜í•˜ê³  ìˆìœ¼ë©°, inference ì†ë„ ë° detection precision ë©´ì—ì„œ ê°œì„ ëœ ê²°ê³¼ë¥¼ ì œê³µí•¨ì„ í™•ì¸í–ˆë‹¤.
- ëª¨ë¸ ì—…ê·¸ë ˆì´ë“œ ê³¼ì •ì—ì„œëŠ” pretrained weightë¥¼ ê³µì‹ repositoryë¡œë¶€í„° ë‹¤ìš´ë¡œë“œí•˜ê³ , ê¸°ì¡´ inference scriptì™€ì˜ í˜¸í™˜ì„±ì„ ê²€í†  ë° ìˆ˜ì •í•˜ì˜€ë‹¤.
- ë™ì¼ test imageì— ëŒ€í•´ YOLOv8nê³¼ YOLOv10nì˜ inference ê²°ê³¼ë¥¼ ë¹„êµí•˜ì—¬ bounding box accuracyì™€ detection latencyì˜ ê°œì„ ì„ ìˆ˜ì¹˜ ë° ì‹œê°ì ìœ¼ë¡œ í™•ì¸í•˜ì˜€ë‹¤.
- ì—…ê·¸ë ˆì´ë“œëœ ëª¨ë¸ì€ í–¥í›„ MobileSAMê³¼ì˜ ì—°ê³„ pipelineì— ì ìš©ë˜ì—ˆë‹¤.

### 2. MobileSAM ë„ì…

- segmentation ëª¨ë¸ë¡œëŠ” ìƒˆë¡­ê²Œ ë“±ì¥í•œ **MobileSAM**ì„ ë„ì…í•˜ì˜€ë‹¤.
- MobileSAMì€ lightweight segmentation modelë¡œì„œ, mobile í™˜ê²½ê³¼ edge computingì— ì í•©í•˜ë„ë¡ ì„¤ê³„ëœ ìµœì‹  ëª¨ë¸ì´ë‹¤.
- ê¸°ì¡´ pipelineì—ì„œëŠ” segmentationì— manual mask í˜¹ì€ ëŒ€ì²´ ë°©ì‹ì„ ì‚¬ìš©í•˜ì˜€ìœ¼ë‚˜, ì´ë²ˆ ë„ì…ì„ í†µí•´ YOLOv10n detection outputì„ ê¸°ë°˜ìœ¼ë¡œ **segmentation maskë¥¼ ìë™ ìƒì„±**í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆë‹¤.
- MobileSAMì˜ pretrained weightë¥¼ ê³µì‹ repositoryì—ì„œ ë‹¤ìš´ë¡œë“œí•˜ê³ , test imageì— ëŒ€í•œ inferenceë¥¼ ì§„í–‰í•˜ì—¬ output mask í’ˆì§ˆê³¼ latencyë¥¼ ì ê²€í•˜ì˜€ë‹¤.
- YOLOv10nì˜ bounding box output â†’ MobileSAMì˜ ROI inputìœ¼ë¡œ ì—°ê³„í•˜ëŠ” pipelineì„ ì¶”ê°€ êµ¬í˜„í•˜ì—¬ detection â†’ segmentation ë‹¨ê³„ì˜ ìë™í™” ë° ì—°ê³„ ê²€ì¦ì„ ì™„ë£Œí•˜ì˜€ë‹¤.
- segmentation outputì€ post-processing ë‹¨ê³„ (thresholding, morphological operation ë“±)ë¥¼ ì¶”ê°€í•˜ì—¬ í–¥í›„ feature extractionê³¼ ì—°ê³„ ê°€ëŠ¥ì„±ì„ ì‹¤í—˜í–ˆë‹¤.

### 3. ë°ì´í„° ì „ì²˜ë¦¬ pipeline ë¦¬ë‰´ì–¼

- feature extraction pipelineì„ ê¸°ì¡´ ë°©ì‹ì—ì„œ **ì™„ì „íˆ ìƒˆë¡­ê²Œ ì¬êµ¬ì„±**í•˜ì˜€ë‹¤.
- ì£¼ìš” ë³€ê²½ ì‚¬í•­:
    - **pose feature extraction**: ê¸°ì¡´ Mediapipe ê¸°ë°˜ ì½”ë“œë¥¼ ë¦¬íŒ©í† ë§í•˜ì—¬ íš¨ìœ¨ì„±ì„ ê°œì„ í•˜ê³  missing data ì²˜ë¦¬ ë¡œì§ ì¶”ê°€
    - **face feature extraction**: eye aspect ratio (EAR) feature ì¶”ì¶œ ë° JSON í¬ë§·ìœ¼ë¡œ ì €ì¥ â†’ downstream taskì—ì„œ ë°”ë¡œ arrayë¡œ ë³€í™˜ ê°€ëŠ¥í•˜ë„ë¡ ë³€ê²½
    - **velocity feature extraction**: í”„ë ˆì„ ê°„ ì¢Œí‘œ ë³€í™”ëŸ‰ ê¸°ë°˜ velocity ê³„ì‚° ë¡œì§ì„ ê°œì„ í•˜ê³  CSV export êµ¬ì¡°ë¥¼ í†µì¼
- ê° featureëŠ” extraction ì‹œ ìµœì†Œ frame ìˆ˜ë¥¼ í™•ì¸í•˜ê³ , ë¶€ì¡±í•  ê²½ìš° ê²½ê³  ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•˜ëŠ” validation ë¡œì§ì„ ì¶”ê°€í•˜ì˜€ë‹¤.
- ëª¨ë“  featureëŠ” ë™ì¼ frame indexì— alignmentê°€ ë§ë„ë¡ trimming ì²˜ë¦¬ â†’ ë°ì´í„° ê°„ temporal misalignment ë°©ì§€
- feature vector í†µí•© í›„ **sliding window ê¸°ë°˜ ì‹œí€€ìŠ¤ ìƒì„± ì½”ë“œ**ë¥¼ ì‘ì„±í•˜ì—¬ dataset augmentation ìˆ˜í–‰ (window length=10, stride=2)
- ìµœì¢…ì ìœ¼ë¡œ pose + face + velocityë¥¼ í•©ì¹œ ì‹œí€€ìŠ¤ dataset(`augmented.npz`)ì„ ìƒì„±í•˜ì˜€ë‹¤.
- ì¶”ê°€ì ìœ¼ë¡œ dataset integrity í™•ì¸ì„ ìœ„í•œ **feature completeness/validity check script**ë¥¼ ì‘ì„±í•˜ì—¬ ê° sampleë³„ feature file ì¡´ì¬ ì—¬ë¶€ ë° ë°ì´í„° ìœ íš¨ì„±ì„ ìë™ ê²€ì¦í•˜ì˜€ë‹¤.

---

## ê²°ê³¼ë¬¼

- YOLOv10n + MobileSAM ê¸°ë°˜ detection & segmentation pipeline êµ¬ì¶• ë° ê²€ì¦ ì™„ë£Œ
- sober / drunk datasetì˜ ëª¨ë“  sampleì— ëŒ€í•´ feature extraction pipeline ì ìš© ì™„ë£Œ
    - feature ë¶€ì¡±í•˜ê±°ë‚˜ ì˜¤ë¥˜ ë°œìƒ sampleì€ integrity check scriptë¡œ ì‹ë³„
- `augmented.npz` (pose + face + velocity í†µí•© ì‹œí€€ìŠ¤ dataset) ìƒì„± ì™„ë£Œ
- integrity check ê²°ê³¼ â†’ feature íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ ë° ê° feature vector length CSV (`feature_integrity_check.csv`) ì¶œë ¥ ì™„ë£Œ
- downstream model (ì˜ˆ: LSTM, MiniGPT-4 ë“±) ì…ë ¥ìš© ë°ì´í„°ì…‹ ì¤€ë¹„ ì™„ë£Œ

---

## ë‹¤ìŒ ì£¼ ê³„íš (ì˜ˆìƒ)

1. **MiniGPT-4 í™˜ê²½ êµ¬ì¶• ë° pretrained weight ë‹¤ìš´ë¡œë“œ**
    - ê³µì‹ GitHub repository clone
    - ì˜ì¡´ì„± ì„¤ì¹˜ (requirements.txt, transformers, bitsandbytes ë“±)
    - pretrained checkpoint ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ í…ŒìŠ¤íŠ¸
2. **multimodal input ì—°ê²° í…ŒìŠ¤íŠ¸**
    - ê¸°ì¡´ feature vector â†’ MiniGPT-4 inputìœ¼ë¡œ ë§¤í•‘ ì‹œë„
    - ë‹¨ì¼ ì´ë¯¸ì§€ caption inference â†’ feature embedding ì¶”ê°€ â†’ multimodal input pipeline ê²€ì¦
3. **baseline inference â†’ fine-tuning ì—¬ë¶€ ê²€í† **
    - zero-shot inference baseline ê²°ê³¼ í‰ê°€
    - í•„ìš” ì‹œ instruction-following dataset ì¤€ë¹„ â†’ fine-tuning ê³„íš ìˆ˜ë¦½
4. **Edge inference ì ìš© ë°©í–¥ì„± ê²€í† **
    - training â†’ server-side inference â†’ model quantization or distillation â†’ edge deployment ê°€ëŠ¥ì„± ë¶„ì„

---

## íŠ¹ì´ì‚¬í•­

- ì¼ë¶€ sober sampleì— ëŒ€í•´ frame ìˆ˜ ë¶€ì¡± (10 frame ë¯¸ë§Œ)ìœ¼ë¡œ feature extraction ë¯¸ì™„ë£Œ
    - â†’ sliding window ì‹œí€€ìŠ¤ ìƒì„± ë¶ˆê°€ sample â†’ ì¦ê°• ëŒ€ìƒ ì œì™¸ ì²˜ë¦¬
- YOLOv10n â†’ MobileSAM ì—°ê³„ ì‹œ image I/O latency ì†Œí­ ì¦ê°€ í™•ì¸ â†’ batch inference ë°©ì•ˆ í•„ìš”ì„± ê³ ë ¤
- ì¶”ì¶œëœ feature vector dimension â†’ downstream model input dimensionê³¼ì˜ í˜¸í™˜ì„± ì¶”ê°€ ì ê²€ í•„ìš”
- **Jetson Nano edge device** ì‚¬ìš© ì˜ˆì •ì´ë‚˜, ì¶”ë¡  latency ë° ë©”ëª¨ë¦¬ ìš”êµ¬ì‚¬í•­ ë¯¸í™•ì •
    - â†’ ì¶”í›„ quantization, pruning ë˜ëŠ” LSTM vs MiniGPT-4 inference ê²½ëŸ‰í™” í•„ìš”ì„± ê²€í† 
- **MiniGPT-4 inference ë°©ì‹** â†’ edge deployment (ë¡œì»¬ inference) or server API inference â†’ ì•„ì§ ê²°ì •ë˜ì§€ ì•ŠìŒ
    - ì´ˆê¸°ì—ëŠ” **server-side inference + API í˜¸ì¶œ** í˜•íƒœë¡œ êµ¬í˜„ í›„, edge compatibility ê²€í†  ì˜ˆì •
- multimodal task ì¢…ë¥˜ â†’ ì´ˆê¸° targetì€ **classification + captioning** taskë¡œ ì„¤ì •

---

## í–¥í›„ ê³„íš (12~14ì£¼ì°¨ ì˜ˆìƒ)

### **12ì£¼ì°¨: MiniGPT-4 baseline inference ë° feature mapping ì‹¤í—˜**
- MiniGPT-4 í™˜ê²½ ì„¤ì • ë° pretrained weight í…ŒìŠ¤íŠ¸
- ë‹¨ì¼ ì´ë¯¸ì§€ caption inference baseline ìˆ˜í–‰
- ê¸°ì¡´ feature vector â†’ multimodal inputìœ¼ë¡œ ì—°ê²° ì‹¤í—˜ (feature embedding or auxiliary input ë°©ì‹ ê²€ì¦)
- inference latency, output í’ˆì§ˆ, ë©”ëª¨ë¦¬ footprint ì¸¡ì • â†’ edge device í˜¸í™˜ì„± ì´ˆì•ˆ ì‘ì„±

### **13ì£¼ì°¨: fine-tuning ë°ì´í„°ì…‹ êµ¬ì¶• ë° í•™ìŠµ ì‹¤í—˜**
- instruction-following dataset ìƒì„± or external dataset ìˆ˜ì§‘
- fine-tuning pipeline êµ¬ì¶• (LoRA, full fine-tuning ì—¬ë¶€ ê²€í† )
- subset datasetìœ¼ë¡œ ì†Œê·œëª¨ fine-tuning test
- baseline â†’ fine-tuned model ì„±ëŠ¥ ë¹„êµ

### **14ì£¼ì°¨: Edge deployment feasibility study**
- Jetson Nano í™˜ê²½ì—ì„œ model inference í…ŒìŠ¤íŠ¸
    - quantization, pruning ì ìš© ì—¬ë¶€ ì‹¤í—˜
- inference API latency vs on-device inference latency ë¹„êµ
- ìµœì¢… multimodal pipeline (YOLOv10n + MobileSAM + MiniGPT-4) end-to-end í‰ê°€
- í•„ìš” ì‹œ fallback model (LSTM or lightweight classifier) ì„±ëŠ¥ ë¹„êµ

---

## ê¸°íƒ€

- ì „ì²´ datasetì˜ feature file ìƒíƒœë¥¼ ìë™ ê²€ì¦í•˜ì—¬ ë¬¸ì œ sample ì‚¬ì „ íŒŒì•…
- feature extraction, augmentation, integrity check codeì— ëŒ€í•œ backup ë° documentation ì‘ì„± ì™„ë£Œ
- í–¥í›„ ì¶”ê°€ ì‹¤í—˜/ë°°í¬ ì‹œ dataset ë³µì œ ê°€ëŠ¥í•˜ë„ë¡ ëª¨ë“  output dataset export ì™„ë£Œ

---

# ğŸ—“ï¸ 12ì£¼ì°¨ ì‘ì—… ë³´ê³ ì„œ

## ê°œìš”

ë³¸ ì£¼ì°¨ì—ì„œëŠ” Vision-Language Multimodal ëª¨ë¸ì¸ **MiniGPT-4**ì˜ ì‹¤í—˜ í™˜ê²½ì„ êµ¬ì„±í•˜ê³ , ì‹¤ì œ pretrained ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ ê°„ë‹¨í•œ inferenceë¥¼ ìˆ˜í–‰í•˜ëŠ” ë°ì— ì¤‘ì ì„ ë‘ì—ˆë‹¤. ì´ë¥¼ í†µí•´ í–¥í›„ feature vectorì™€ ì—°ê³„ëœ multimodal ì…ë ¥ ì‹¤í—˜ ê¸°ë°˜ì„ ë§ˆë ¨í•˜ì˜€ë‹¤.

---

## ì£¼ìš” ì‘ì—… ë‚´ìš©

### 1. MiniGPT-4 í™˜ê²½ êµ¬ì„±

- MiniGPT-4 ê³µì‹ GitHub ì €ì¥ì†Œ í´ë¡ 
- ì˜ì¡´ì„± ì„¤ì¹˜ (conda í™˜ê²½ êµ¬ì„± ë° `environment.yml` í™œìš©)
- Python 3.10 ì´ìƒì—ì„œ ì‹¤í–‰ í™˜ê²½ êµ¬ì¶•
- inference ì‹¤í–‰ì„ ìœ„í•œ `demo.py`, `minigpt4_eval.yaml` ë“± êµ¬ì„± ìš”ì†Œ í™•ì¸

---

### 2. LLaMA2 7B ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ì„¤ì •

- Hugging Faceì—ì„œ **meta-llama/Llama-2-7b-chat-hf** ëª¨ë¸ì— ëŒ€í•œ access ìš”ì²­ â†’ ìŠ¹ì¸
- huggingface_hub ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í™œìš©í•˜ì—¬ Pythonìœ¼ë¡œ ë¡œì»¬ì— weight ë‹¤ìš´ë¡œë“œ
- ì•½ 20GB ëª¨ë¸ ì••ì¶• â†’ Google Driveì— ì—…ë¡œë“œ
- Colabì—ì„œ ì••ì¶• í•´ì œ ë° ì¶”ë¡  í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ê²½ë¡œ ì„¤ì •

---

### 3. Colab í™˜ê²½ì—ì„œ ëª¨ë¸ ì‹¤í–‰

- Google Driveì— ì—…ë¡œë“œí•œ ëª¨ë¸ zip íŒŒì¼ ë§ˆìš´íŠ¸ ë° ì••ì¶• í•´ì œ
- config íŒŒì¼(`minigpt4_llama2_eval.yaml`) ë‚´ weight ê²½ë¡œ ìˆ˜ì •
- `demo.py` ì‹¤í–‰ì„ í†µí•´ ì´ë¯¸ì§€ ê¸°ë°˜ promptì— ëŒ€í•œ ì‘ë‹µ ì¶œë ¥ í™•ì¸
- A100 GPU í™˜ê²½ì—ì„œ ì •ìƒ ì‘ë™ ë° ì‘ë‹µ í™•ì¸

---

## ê²°ê³¼ë¬¼

- MiniGPT-4 í™˜ê²½ ì •ìƒ êµ¬ì¶•
- LLaMA2 ëª¨ë¸ ë¡œë“œ ë° Colab ì—°ë™ ì™„ë£Œ
- ê°„ë‹¨í•œ ì´ë¯¸ì§€ ê¸°ë°˜ inference ì„±ê³µ
- í–¥í›„ ì»¤ìŠ¤í„°ë§ˆì´ì§• ë° feature vector ì—°ë™ì„ ìœ„í•œ ê¸°ë°˜ í™•ë³´

---

## íŠ¹ì´ì‚¬í•­

- Hugging Face ëª¨ë¸ ì ‘ê·¼ ê¶Œí•œ ì‹ ì²­ â†’ ìŠ¹ì¸ê¹Œì§€ ìˆ˜ì‹œê°„ ~ 1ì¼ ì†Œìš”
- ëª¨ë¸ í¬ê¸°(20GB+)ë¡œ ì¸í•´ ë¡œì»¬ â†” Colab ê°„ ì••ì¶• ë° ì „ì†¡ ì‹œê°„ì´ ë‹¤ì†Œ ì†Œìš”ë¨
- ë¡œì»¬ì—ì„œëŠ” GPU ì„±ëŠ¥ ì œí•œìœ¼ë¡œ inference ì–´ë ¤ì›€ â†’ Colab (A100 í™˜ê²½) ê¶Œì¥

---

## âœ… ë‹¤ìŒ ì£¼ ê³„íš (13ì£¼ì°¨)

1. ê¸°ì¡´ pose/face/velocity feature vectorë¥¼ í™œìš©í•œ **multimodal input êµ¬ì¡° ì„¤ê³„**
2. MiniGPT-4 encoderì˜ ì…ë ¥ êµ¬ì¡°ë¥¼ ë¶„ì„í•˜ì—¬ feature vectorì™€ ì—°ë™ ì‹¤í—˜ ì§„í–‰
3. baseline zero-shot inference ê²°ê³¼ ë¶„ì„ â†’ fine-tuning í•„ìš” ì—¬ë¶€ ê²€í† 
4. ì¶”ë¡  ì†ë„/ì„±ëŠ¥ ê¸°ì¤€ìœ¼ë¡œ edge deployment ê°€ëŠ¥ì„± ê²€í† 

---
